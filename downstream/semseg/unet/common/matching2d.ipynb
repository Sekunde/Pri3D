{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawMatches(img1, kp1, img2, kp2, matches, color=None): \n",
    "    \"\"\"Draws lines between matching keypoints of two images.  \n",
    "    Keypoints not in a matching pair are not drawn.\n",
    "\n",
    "    Places the images side by side in a new image and draws circles \n",
    "    around each keypoint, with line segments connecting matching pairs.\n",
    "    You can tweak the r, thickness, and figsize values as needed.\n",
    "\n",
    "    Args:\n",
    "        img1: An openCV image ndarray in a grayscale or color format.\n",
    "        kp1: A list of cv2.KeyPoint objects for img1.\n",
    "        img2: An openCV image ndarray of the same format and with the same \n",
    "        element type as img1.\n",
    "        kp2: A list of cv2.KeyPoint objects for img2.\n",
    "        matches: A list of DMatch objects whose trainIdx attribute refers to \n",
    "        img1 keypoints and whose queryIdx attribute refers to img2 keypoints.\n",
    "        color: The color of the circles and connecting lines drawn on the images.  \n",
    "        A 3-tuple for color images, a scalar for grayscale images.  If None, these\n",
    "        values are randomly generated.  \n",
    "    \"\"\"\n",
    "    # We're drawing them side by side.  Get dimensions accordingly.\n",
    "    # Handle both color and grayscale images.\n",
    "    if len(img1.shape) == 3:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], img1.shape[2])\n",
    "    elif len(img1.shape) == 2:\n",
    "        new_shape = (max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1])\n",
    "    new_img = np.zeros(new_shape, type(img1.flat[0]))  \n",
    "    # Place images onto the new image.\n",
    "    new_img[0:img1.shape[0],0:img1.shape[1]] = img1\n",
    "    new_img[0:img2.shape[0],img1.shape[1]:img1.shape[1]+img2.shape[1]] = img2\n",
    "    \n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    r = 1\n",
    "    thickness = 2\n",
    "    if color:\n",
    "        c = color\n",
    "    for m in matches:\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        if not color: \n",
    "            c = np.random.randint(0,256,3) if len(img1.shape) == 3 else np.random.randint(0,256)\n",
    "            c = (int(c[0]), int(c[1]), int(c[2]))\n",
    "        # So the keypoint locs are stored as a tuple of floats.  cv2.line(), like most other things,\n",
    "        # wants locs as a tuple of ints.\n",
    "        end1 = tuple(np.round(kp1[m.trainIdx].pt).astype(int))\n",
    "        end2 = tuple(np.round(kp2[m.queryIdx].pt).astype(int) + np.array([img1.shape[1], 0]))\n",
    "        cv2.line(new_img, end1, end2, c, thickness)\n",
    "        cv2.circle(new_img, end1, r, c, thickness)\n",
    "        cv2.circle(new_img, end2, r, c, thickness)\n",
    "    return new_img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jhou/Dropbox/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-edc927bed78f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdes1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mscene_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_pair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pair'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_pair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jhou/Dropbox/data'"
     ]
    }
   ],
   "source": [
    "path = '/home/jhou/Dropbox/data'\n",
    "kp1 = []\n",
    "kp2 = []\n",
    "des1 = []\n",
    "des2 = []\n",
    "for scene_id in os.listdir(path):\n",
    "    for image_pair in os.listdir(os.path.join(path, scene_id, 'pair')):\n",
    "        image1 = image_pair.split('_')[0]\n",
    "        image2 = image_pair.split('_')[1]\n",
    "        img1 = cv2.imread('/home/jhou/Dropbox/data/{}/color/{}.png'.format(scene_id, image1))          # queryImage\n",
    "        img2 = cv2.imread('/home/jhou/Dropbox/data/{}/color/{}.png'.format(scene_id, image2))          # queryImage\n",
    "        # resize image\n",
    "        img1 = cv2.resize(img1, (320,240), interpolation = cv2.INTER_AREA)\n",
    "        img2 = cv2.resize(img2, (320,240), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        features = torch.load(os.path.join(path, scene_id, 'pair', image_pair))\n",
    "        feature1 = features[1]\n",
    "        feature2 = features[0]\n",
    "        feature1 = feature1 / torch.norm(feature1, p=2, dim=0, keepdim=True)\n",
    "        feature2 = feature2 / torch.norm(feature2, p=2, dim=0, keepdim=True)\n",
    "        for x in range(feature1.shape[2]):\n",
    "            for y in range(feature1.shape[1]):\n",
    "                kp1.append(cv2.KeyPoint(x*2,y*2,30))\n",
    "                kp2.append(cv2.KeyPoint(x*2,y*2,30))\n",
    "                des1.append(feature1[:,y,x].numpy())\n",
    "                des2.append(feature2[:,y,x].numpy())\n",
    "        des1 = np.stack(des1)\n",
    "        des2 = np.stack(des2)\n",
    "\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "        matches = bf.match(des1,des2)\n",
    "        matches = sorted(matches, key = lambda x:x.distance)\n",
    "        img3 = drawMatches(img1,kp1,img2,kp2,matches[:50], color=False)\n",
    "        plt.rcParams['figure.dpi'] = 300\n",
    "        img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
    "        plt.imsave('test.png', img3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}