DATA:
  data_root: ''
  train_list: list
  val_list: val
  classes: 40

TRAIN:
  arch: psp
  layers: 50
  sync_bn: True  # adopt sync_bn or not
  train_h: 473
  train_w: 473
  scale_min: 0.5  # minimum random scale
  scale_max: 2.0  # maximum random scale
  rotate_min: -10  # minimum random rotate
  rotate_max: 10  # maximum random rotate
  zoom_factor: 8  # zoom factor for final prediction during training, be in [1, 2, 4, 8]
  ignore_label: 255
  aux_weight: 0.4
  train_gpu: [0,1,2,3]
  workers: 16  # data loader workers
  batch_size: 16  # batch size for training
  batch_size_val: 8  # batch size for validation during training, memory and speed tradeoff
  base_lr: 0.01
  epochs: 50
  start_epoch: 0
  power: 0.9
  momentum: 0.9
  weight_decay: 0.0001
  manual_seed:
  print_freq: 10
  save_freq: 1
  save_path: exp/ade20k/pspnet50/model
  weight:  #initmodel/train_epoch_1init.pth #exp/ade20k/pspnet50/model/train_epoch_100.pth #/media/lzz/f1cc9be0-388f-421d-a473-5b33192a9893/semseg_feature/initmodel/init.pth
  resume: #exp/ade20k/pspnet50/model/train_epoch_50.pth 
  evaluate: False  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend

TEST:
  test_list: list_val #list_val
  split: val  # split in [train, val and test]
  base_size: 1297  # based size for scaling
  test_h: 473
  test_w: 473
  scales: [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]  # evaluation scales, ms as [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]
  has_prediction: False  # has prediction already or not
  index_start: 0  # evaluation start index in list
  index_step: 0  # evaluation step index in list, 0 means to end
  test_gpu: [0]
  model_path: exp/scannet/pspnet50/model/train_epoch_50.pth  # evaluation model path
  save_folder: exp/scannet/pspnet50/result/val # results save folder
  colors_path: dataset/scannet/scannet_colors.txt  # path of dataset colors
  names_path: dataset/scannet/scannet_names.txt  # path of dataset category names
